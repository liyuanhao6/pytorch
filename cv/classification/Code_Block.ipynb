{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"We use \" + DEVICE)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "# CIFAR10\n",
    "transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "transform = transforms.Compose([\n",
    "                                transforms.Resize([256, 256]),\n",
    "                                transforms.RandomCrop(224),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomVerticalFlip(),\n",
    "                                transforms.RandomRotation(15),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    (0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_db and val_db\n",
    "train_db, val_db = torch.utils.data.random_split(db, [40000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader\n",
    "torch.utils.data.DataLoader(\n",
    "    db,\n",
    "    batch_size=batch_size,\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")\n",
    "# val_loader or test_loader\n",
    "torch.utils.data.DataLoader(\n",
    "    db,\n",
    "    batch_size=batch_size,\n",
    "    drop_last=True,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}\\n')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\\n')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "# method\n",
    "early_stopping(val_loss=validate_loss, model=net)\n",
    "        \n",
    "if early_stopping.early_stop:\n",
    "    print(\"\\nEarly stopping\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer and scheduler\n",
    "net = model().to(DEVICE)\n",
    "criteon = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = optim.SGD(net.parameters(),\n",
    "                      lr=learning_rate,\n",
    "                      momentum=momentum,\n",
    "                      )\n",
    "# optimizer.step() in each small train loop\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, 'min', min_lr=1e-4, factor=0.5, patience=3)\n",
    "# scheduler.step() in each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "summary(net, (batch, h, w))\n",
    "print(f'parameters_count: {count_parameters(net)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function\n",
    "def train(epoch):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    train_correct = 0\n",
    "    net.train()\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        data, label = data.to(DEVICE), label.to(DEVICE)\n",
    "\n",
    "        logits = net(data)\n",
    "        loss = criteon(logits, label)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        train_correct += torch.eq(pred, label).float().sum().item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch + 1, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    \n",
    "    train_loss /= len(val_loader.dataset)\n",
    "    train_acc = 1. * train_correct / len(train_loader.dataset)\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate function\n",
    "def validate():\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    val_correct = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label in val_loader:\n",
    "            data, label = data.to(DEVICE), label.to(DEVICE)\n",
    "\n",
    "            logits = net(data)\n",
    "            val_loss += criteon(logits, label).item()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            val_correct += torch.eq(pred, label).float().sum().item()\n",
    "            \n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_acc = 1. * val_correct / len(val_loader.dataset)\n",
    "\n",
    "    print('VAL set: Average loss: {:.6f}, Accuracy: {}/{} ({:.1f}%)'.format(\n",
    "        val_loss, val_correct, len(val_loader.dataset), 100. * val_acc))\n",
    "    \n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function\n",
    "def test():\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    test_correct = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data, label = data.to(DEVICE), label.to(DEVICE)\n",
    "\n",
    "            logits = net(data)\n",
    "            test_loss += criteon(logits, label).item()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            test_correct += torch.eq(pred, label).float().sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 1. * test_correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, test_correct, len(test_loader.dataset), 100. * test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss function\n",
    "def plot_loss(train_losses, valid_losses):\n",
    "    plt.style.use('seaborn')\n",
    "    fig, ax = plt.subplots(figsize=(8, 4.5))\n",
    "    \n",
    "    # find position of lowest validation loss\n",
    "    minpos = valid_losses.index(min(valid_losses))\n",
    "\n",
    "    train_losses = np.array(train_losses)\n",
    "    valid_losses = np.array(valid_losses)\n",
    "\n",
    "    ax.plot(train_losses, color='blue', label='Training loss')\n",
    "    ax.plot(valid_losses, color='red', label='Validation loss')\n",
    "    ax.set(title=\"Loss over epochs\",\n",
    "           xlabel='Epoch',\n",
    "           ylabel='Loss')\n",
    "    \n",
    "    plt.axvline(minpos, linestyle='--', color='r',\n",
    "                label='Early Stopping Checkpoint')\n",
    "    ax.legend()\n",
    "\n",
    "    # change the plot style to default\n",
    "    plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot acc function\n",
    "def plot_acc(train_accuracies, validate_accuracies):\n",
    "    plt.style.use('seaborn')\n",
    "    fig, ax = plt.subplots(figsize=(8, 4.5))\n",
    "\n",
    "    # find position of lowest validation loss\n",
    "    maxpos = validate_accuracies.index(max(validate_accuracies))\n",
    "    \n",
    "    train_accuracies = np.array(train_accuracies)\n",
    "    validate_accuracies = np.array(validate_accuracies)\n",
    "    \n",
    "    ax.plot(train_accuracies, color='blue', label='Training accuracy')\n",
    "    ax.plot(validate_accuracies, color='red', label='Validation accuracy')\n",
    "    ax.set(title=\"Accuracy over epochs\",\n",
    "           xlabel='Epoch',\n",
    "           ylabel='Accuracy')\n",
    "    \n",
    "    plt.axvline(maxpos, linestyle='--', color='r',\n",
    "                label='Early Stopping Checkpoint')\n",
    "    ax.legend()\n",
    "\n",
    "    # change the plot style to default\n",
    "    plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main funciton\n",
    "—— train function\n",
    "—— validate function\n",
    "—— scheduler.step()\n",
    "—— early_stopping()\n",
    "—— plot loss function\n",
    "—— plot acc function\n",
    "—— test function\n",
    "\n",
    "def main():\n",
    "    train_losses = []\n",
    "    validate_losses = []\n",
    "    train_accuracies = []\n",
    "    validate_accuracies = []\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_accuracy = train(epoch)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        validate_loss, validate_accuracy = validate()\n",
    "        validate_losses.append(validate_loss)\n",
    "        validate_accuracies.append(validate_accuracy)\n",
    "        scheduler.step(validate_loss)\n",
    "        early_stopping(val_loss=validate_loss, model=net)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"\\nEarly stopping\\n\")\n",
    "            break\n",
    "\n",
    "    plot_loss(train_losses, validate_losses)\n",
    "    plot_acc(train_accuracies, validate_accuracies)\n",
    "    \n",
    "    # load the last checkpoint with the best model\n",
    "    net.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pictures\n",
    "CIFAR_dict = {0: 'airplane',\n",
    "              1: 'automobile',\n",
    "              2: 'brid',\n",
    "              3: 'cat',\n",
    "              4: 'deer',\n",
    "              5: 'dog',\n",
    "              6: 'frog',\n",
    "              7: 'horse',\n",
    "              8: 'ship',\n",
    "              9: 'truck'}\n",
    "\n",
    "ROW_IMG = 10\n",
    "N_ROWS = 5\n",
    "\n",
    "fig = plt.figure()\n",
    "for index in range(1, ROW_IMG * N_ROWS + 1):\n",
    "    plt.subplot(N_ROWS, ROW_IMG, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(test_db.data[index])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        logits = net(test_db[index][0].unsqueeze(0).to(DEVICE))\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "\n",
    "    title = f'{CIFAR_dict[int(torch.argmax(probs))]} ({torch.max(probs * 100):.0f}%)'\n",
    "\n",
    "    plt.title(title, fontsize=4)\n",
    "\n",
    "fig.suptitle('MobileNetV1 - predictions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
